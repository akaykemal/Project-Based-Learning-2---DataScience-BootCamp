{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca555202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, InputLayer, Reshape, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b57ddee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the CIFAR10 dataset\n",
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "873396f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 91s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# load the CIFAR10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e53a61ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (10000, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a4f6a9",
   "metadata": {},
   "source": [
    "There is a total of 60000 images of 10 different classes naming , ,, , ,,,,,. All the images are of size 32Ã—32. There are in total 50000 train images and 10000 test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5a3d151",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94f86690",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [8],\n",
       "       [8],\n",
       "       ...,\n",
       "       [5],\n",
       "       [1],\n",
       "       [7]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6573735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 59,  62,  63],\n",
       "         [ 43,  46,  45],\n",
       "         [ 50,  48,  43],\n",
       "         ...,\n",
       "         [158, 132, 108],\n",
       "         [152, 125, 102],\n",
       "         [148, 124, 103]],\n",
       "\n",
       "        [[ 16,  20,  20],\n",
       "         [  0,   0,   0],\n",
       "         [ 18,   8,   0],\n",
       "         ...,\n",
       "         [123,  88,  55],\n",
       "         [119,  83,  50],\n",
       "         [122,  87,  57]],\n",
       "\n",
       "        [[ 25,  24,  21],\n",
       "         [ 16,   7,   0],\n",
       "         [ 49,  27,   8],\n",
       "         ...,\n",
       "         [118,  84,  50],\n",
       "         [120,  84,  50],\n",
       "         [109,  73,  42]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[208, 170,  96],\n",
       "         [201, 153,  34],\n",
       "         [198, 161,  26],\n",
       "         ...,\n",
       "         [160, 133,  70],\n",
       "         [ 56,  31,   7],\n",
       "         [ 53,  34,  20]],\n",
       "\n",
       "        [[180, 139,  96],\n",
       "         [173, 123,  42],\n",
       "         [186, 144,  30],\n",
       "         ...,\n",
       "         [184, 148,  94],\n",
       "         [ 97,  62,  34],\n",
       "         [ 83,  53,  34]],\n",
       "\n",
       "        [[177, 144, 116],\n",
       "         [168, 129,  94],\n",
       "         [179, 142,  87],\n",
       "         ...,\n",
       "         [216, 184, 140],\n",
       "         [151, 118,  84],\n",
       "         [123,  92,  72]]],\n",
       "\n",
       "\n",
       "       [[[154, 177, 187],\n",
       "         [126, 137, 136],\n",
       "         [105, 104,  95],\n",
       "         ...,\n",
       "         [ 91,  95,  71],\n",
       "         [ 87,  90,  71],\n",
       "         [ 79,  81,  70]],\n",
       "\n",
       "        [[140, 160, 169],\n",
       "         [145, 153, 154],\n",
       "         [125, 125, 118],\n",
       "         ...,\n",
       "         [ 96,  99,  78],\n",
       "         [ 77,  80,  62],\n",
       "         [ 71,  73,  61]],\n",
       "\n",
       "        [[140, 155, 164],\n",
       "         [139, 146, 149],\n",
       "         [115, 115, 112],\n",
       "         ...,\n",
       "         [ 79,  82,  64],\n",
       "         [ 68,  70,  55],\n",
       "         [ 67,  69,  55]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[175, 167, 166],\n",
       "         [156, 154, 160],\n",
       "         [154, 160, 170],\n",
       "         ...,\n",
       "         [ 42,  34,  36],\n",
       "         [ 61,  53,  57],\n",
       "         [ 93,  83,  91]],\n",
       "\n",
       "        [[165, 154, 128],\n",
       "         [156, 152, 130],\n",
       "         [159, 161, 142],\n",
       "         ...,\n",
       "         [103,  93,  96],\n",
       "         [123, 114, 120],\n",
       "         [131, 121, 131]],\n",
       "\n",
       "        [[163, 148, 120],\n",
       "         [158, 148, 122],\n",
       "         [163, 156, 133],\n",
       "         ...,\n",
       "         [143, 133, 139],\n",
       "         [143, 134, 142],\n",
       "         [143, 133, 144]]],\n",
       "\n",
       "\n",
       "       [[[255, 255, 255],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         ...,\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[113, 120, 112],\n",
       "         [111, 118, 111],\n",
       "         [105, 112, 106],\n",
       "         ...,\n",
       "         [ 72,  81,  80],\n",
       "         [ 72,  80,  79],\n",
       "         [ 72,  80,  79]],\n",
       "\n",
       "        [[111, 118, 110],\n",
       "         [104, 111, 104],\n",
       "         [ 99, 106,  98],\n",
       "         ...,\n",
       "         [ 68,  75,  73],\n",
       "         [ 70,  76,  75],\n",
       "         [ 78,  84,  82]],\n",
       "\n",
       "        [[106, 113, 105],\n",
       "         [ 99, 106,  98],\n",
       "         [ 95, 102,  94],\n",
       "         ...,\n",
       "         [ 78,  85,  83],\n",
       "         [ 79,  85,  83],\n",
       "         [ 80,  86,  84]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 35, 178, 235],\n",
       "         [ 40, 176, 239],\n",
       "         [ 42, 176, 241],\n",
       "         ...,\n",
       "         [ 99, 177, 219],\n",
       "         [ 79, 147, 197],\n",
       "         [ 89, 148, 189]],\n",
       "\n",
       "        [[ 57, 182, 234],\n",
       "         [ 44, 184, 250],\n",
       "         [ 50, 183, 240],\n",
       "         ...,\n",
       "         [156, 182, 200],\n",
       "         [141, 177, 206],\n",
       "         [116, 149, 175]],\n",
       "\n",
       "        [[ 98, 197, 237],\n",
       "         [ 64, 189, 252],\n",
       "         [ 69, 192, 245],\n",
       "         ...,\n",
       "         [188, 195, 206],\n",
       "         [119, 135, 147],\n",
       "         [ 61,  79,  90]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 73,  79,  77],\n",
       "         [ 53,  63,  68],\n",
       "         [ 54,  68,  80],\n",
       "         ...,\n",
       "         [ 17,  40,  64],\n",
       "         [ 21,  36,  51],\n",
       "         [ 33,  48,  49]],\n",
       "\n",
       "        [[ 61,  68,  75],\n",
       "         [ 55,  70,  86],\n",
       "         [ 57,  79, 103],\n",
       "         ...,\n",
       "         [ 24,  48,  72],\n",
       "         [ 17,  35,  53],\n",
       "         [  7,  23,  32]],\n",
       "\n",
       "        [[ 44,  56,  73],\n",
       "         [ 46,  66,  88],\n",
       "         [ 49,  77, 105],\n",
       "         ...,\n",
       "         [ 27,  52,  77],\n",
       "         [ 21,  43,  66],\n",
       "         [ 12,  31,  50]]],\n",
       "\n",
       "\n",
       "       [[[189, 211, 240],\n",
       "         [186, 208, 236],\n",
       "         [185, 207, 235],\n",
       "         ...,\n",
       "         [175, 195, 224],\n",
       "         [172, 194, 222],\n",
       "         [169, 194, 220]],\n",
       "\n",
       "        [[194, 210, 239],\n",
       "         [191, 207, 236],\n",
       "         [190, 206, 235],\n",
       "         ...,\n",
       "         [173, 192, 220],\n",
       "         [171, 191, 218],\n",
       "         [167, 190, 216]],\n",
       "\n",
       "        [[208, 219, 244],\n",
       "         [205, 216, 240],\n",
       "         [204, 215, 239],\n",
       "         ...,\n",
       "         [175, 191, 217],\n",
       "         [172, 190, 216],\n",
       "         [169, 191, 215]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[207, 199, 181],\n",
       "         [203, 195, 175],\n",
       "         [203, 196, 173],\n",
       "         ...,\n",
       "         [135, 132, 127],\n",
       "         [162, 158, 150],\n",
       "         [168, 163, 151]],\n",
       "\n",
       "        [[198, 190, 170],\n",
       "         [189, 181, 159],\n",
       "         [180, 172, 147],\n",
       "         ...,\n",
       "         [178, 171, 160],\n",
       "         [175, 169, 156],\n",
       "         [175, 169, 154]],\n",
       "\n",
       "        [[198, 189, 173],\n",
       "         [189, 181, 162],\n",
       "         [178, 170, 149],\n",
       "         ...,\n",
       "         [195, 184, 169],\n",
       "         [196, 189, 171],\n",
       "         [195, 190, 171]]],\n",
       "\n",
       "\n",
       "       [[[229, 229, 239],\n",
       "         [236, 237, 247],\n",
       "         [234, 236, 247],\n",
       "         ...,\n",
       "         [217, 219, 233],\n",
       "         [221, 223, 234],\n",
       "         [222, 223, 233]],\n",
       "\n",
       "        [[222, 221, 229],\n",
       "         [239, 239, 249],\n",
       "         [233, 234, 246],\n",
       "         ...,\n",
       "         [223, 223, 236],\n",
       "         [227, 228, 238],\n",
       "         [210, 211, 220]],\n",
       "\n",
       "        [[213, 206, 211],\n",
       "         [234, 232, 239],\n",
       "         [231, 233, 244],\n",
       "         ...,\n",
       "         [220, 220, 232],\n",
       "         [220, 219, 232],\n",
       "         [202, 203, 215]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[150, 143, 135],\n",
       "         [140, 135, 127],\n",
       "         [132, 127, 120],\n",
       "         ...,\n",
       "         [224, 222, 218],\n",
       "         [230, 228, 225],\n",
       "         [241, 241, 238]],\n",
       "\n",
       "        [[137, 132, 126],\n",
       "         [130, 127, 120],\n",
       "         [125, 121, 115],\n",
       "         ...,\n",
       "         [181, 180, 178],\n",
       "         [202, 201, 198],\n",
       "         [212, 211, 207]],\n",
       "\n",
       "        [[122, 119, 114],\n",
       "         [118, 116, 110],\n",
       "         [120, 116, 111],\n",
       "         ...,\n",
       "         [179, 177, 173],\n",
       "         [164, 164, 162],\n",
       "         [163, 163, 161]]]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e4559c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fa52ed5e20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0],cmap='gray') # first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2f8d166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fa53a652e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[-1],cmap='gray') # last image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb5e40c",
   "metadata": {},
   "source": [
    "### Normalize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43214306",
   "metadata": {},
   "source": [
    "We know that the pixel values for each image in the dataset are unsigned integers in the range between no color and full color, or 0 and 255.<br>\n",
    "So to scale them we normalize the pixel values by rescaling them to the range [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b39bd01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train/255.0\n",
    "x_test=x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1193a388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.23137255, 0.24313725, 0.24705882],\n",
       "         [0.16862745, 0.18039216, 0.17647059],\n",
       "         [0.19607843, 0.18823529, 0.16862745],\n",
       "         ...,\n",
       "         [0.61960784, 0.51764706, 0.42352941],\n",
       "         [0.59607843, 0.49019608, 0.4       ],\n",
       "         [0.58039216, 0.48627451, 0.40392157]],\n",
       "\n",
       "        [[0.0627451 , 0.07843137, 0.07843137],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.07058824, 0.03137255, 0.        ],\n",
       "         ...,\n",
       "         [0.48235294, 0.34509804, 0.21568627],\n",
       "         [0.46666667, 0.3254902 , 0.19607843],\n",
       "         [0.47843137, 0.34117647, 0.22352941]],\n",
       "\n",
       "        [[0.09803922, 0.09411765, 0.08235294],\n",
       "         [0.0627451 , 0.02745098, 0.        ],\n",
       "         [0.19215686, 0.10588235, 0.03137255],\n",
       "         ...,\n",
       "         [0.4627451 , 0.32941176, 0.19607843],\n",
       "         [0.47058824, 0.32941176, 0.19607843],\n",
       "         [0.42745098, 0.28627451, 0.16470588]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.81568627, 0.66666667, 0.37647059],\n",
       "         [0.78823529, 0.6       , 0.13333333],\n",
       "         [0.77647059, 0.63137255, 0.10196078],\n",
       "         ...,\n",
       "         [0.62745098, 0.52156863, 0.2745098 ],\n",
       "         [0.21960784, 0.12156863, 0.02745098],\n",
       "         [0.20784314, 0.13333333, 0.07843137]],\n",
       "\n",
       "        [[0.70588235, 0.54509804, 0.37647059],\n",
       "         [0.67843137, 0.48235294, 0.16470588],\n",
       "         [0.72941176, 0.56470588, 0.11764706],\n",
       "         ...,\n",
       "         [0.72156863, 0.58039216, 0.36862745],\n",
       "         [0.38039216, 0.24313725, 0.13333333],\n",
       "         [0.3254902 , 0.20784314, 0.13333333]],\n",
       "\n",
       "        [[0.69411765, 0.56470588, 0.45490196],\n",
       "         [0.65882353, 0.50588235, 0.36862745],\n",
       "         [0.70196078, 0.55686275, 0.34117647],\n",
       "         ...,\n",
       "         [0.84705882, 0.72156863, 0.54901961],\n",
       "         [0.59215686, 0.4627451 , 0.32941176],\n",
       "         [0.48235294, 0.36078431, 0.28235294]]],\n",
       "\n",
       "\n",
       "       [[[0.60392157, 0.69411765, 0.73333333],\n",
       "         [0.49411765, 0.5372549 , 0.53333333],\n",
       "         [0.41176471, 0.40784314, 0.37254902],\n",
       "         ...,\n",
       "         [0.35686275, 0.37254902, 0.27843137],\n",
       "         [0.34117647, 0.35294118, 0.27843137],\n",
       "         [0.30980392, 0.31764706, 0.2745098 ]],\n",
       "\n",
       "        [[0.54901961, 0.62745098, 0.6627451 ],\n",
       "         [0.56862745, 0.6       , 0.60392157],\n",
       "         [0.49019608, 0.49019608, 0.4627451 ],\n",
       "         ...,\n",
       "         [0.37647059, 0.38823529, 0.30588235],\n",
       "         [0.30196078, 0.31372549, 0.24313725],\n",
       "         [0.27843137, 0.28627451, 0.23921569]],\n",
       "\n",
       "        [[0.54901961, 0.60784314, 0.64313725],\n",
       "         [0.54509804, 0.57254902, 0.58431373],\n",
       "         [0.45098039, 0.45098039, 0.43921569],\n",
       "         ...,\n",
       "         [0.30980392, 0.32156863, 0.25098039],\n",
       "         [0.26666667, 0.2745098 , 0.21568627],\n",
       "         [0.2627451 , 0.27058824, 0.21568627]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.68627451, 0.65490196, 0.65098039],\n",
       "         [0.61176471, 0.60392157, 0.62745098],\n",
       "         [0.60392157, 0.62745098, 0.66666667],\n",
       "         ...,\n",
       "         [0.16470588, 0.13333333, 0.14117647],\n",
       "         [0.23921569, 0.20784314, 0.22352941],\n",
       "         [0.36470588, 0.3254902 , 0.35686275]],\n",
       "\n",
       "        [[0.64705882, 0.60392157, 0.50196078],\n",
       "         [0.61176471, 0.59607843, 0.50980392],\n",
       "         [0.62352941, 0.63137255, 0.55686275],\n",
       "         ...,\n",
       "         [0.40392157, 0.36470588, 0.37647059],\n",
       "         [0.48235294, 0.44705882, 0.47058824],\n",
       "         [0.51372549, 0.4745098 , 0.51372549]],\n",
       "\n",
       "        [[0.63921569, 0.58039216, 0.47058824],\n",
       "         [0.61960784, 0.58039216, 0.47843137],\n",
       "         [0.63921569, 0.61176471, 0.52156863],\n",
       "         ...,\n",
       "         [0.56078431, 0.52156863, 0.54509804],\n",
       "         [0.56078431, 0.5254902 , 0.55686275],\n",
       "         [0.56078431, 0.52156863, 0.56470588]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         ...,\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         ...,\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.44313725, 0.47058824, 0.43921569],\n",
       "         [0.43529412, 0.4627451 , 0.43529412],\n",
       "         [0.41176471, 0.43921569, 0.41568627],\n",
       "         ...,\n",
       "         [0.28235294, 0.31764706, 0.31372549],\n",
       "         [0.28235294, 0.31372549, 0.30980392],\n",
       "         [0.28235294, 0.31372549, 0.30980392]],\n",
       "\n",
       "        [[0.43529412, 0.4627451 , 0.43137255],\n",
       "         [0.40784314, 0.43529412, 0.40784314],\n",
       "         [0.38823529, 0.41568627, 0.38431373],\n",
       "         ...,\n",
       "         [0.26666667, 0.29411765, 0.28627451],\n",
       "         [0.2745098 , 0.29803922, 0.29411765],\n",
       "         [0.30588235, 0.32941176, 0.32156863]],\n",
       "\n",
       "        [[0.41568627, 0.44313725, 0.41176471],\n",
       "         [0.38823529, 0.41568627, 0.38431373],\n",
       "         [0.37254902, 0.4       , 0.36862745],\n",
       "         ...,\n",
       "         [0.30588235, 0.33333333, 0.3254902 ],\n",
       "         [0.30980392, 0.33333333, 0.3254902 ],\n",
       "         [0.31372549, 0.3372549 , 0.32941176]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.1372549 , 0.69803922, 0.92156863],\n",
       "         [0.15686275, 0.69019608, 0.9372549 ],\n",
       "         [0.16470588, 0.69019608, 0.94509804],\n",
       "         ...,\n",
       "         [0.38823529, 0.69411765, 0.85882353],\n",
       "         [0.30980392, 0.57647059, 0.77254902],\n",
       "         [0.34901961, 0.58039216, 0.74117647]],\n",
       "\n",
       "        [[0.22352941, 0.71372549, 0.91764706],\n",
       "         [0.17254902, 0.72156863, 0.98039216],\n",
       "         [0.19607843, 0.71764706, 0.94117647],\n",
       "         ...,\n",
       "         [0.61176471, 0.71372549, 0.78431373],\n",
       "         [0.55294118, 0.69411765, 0.80784314],\n",
       "         [0.45490196, 0.58431373, 0.68627451]],\n",
       "\n",
       "        [[0.38431373, 0.77254902, 0.92941176],\n",
       "         [0.25098039, 0.74117647, 0.98823529],\n",
       "         [0.27058824, 0.75294118, 0.96078431],\n",
       "         ...,\n",
       "         [0.7372549 , 0.76470588, 0.80784314],\n",
       "         [0.46666667, 0.52941176, 0.57647059],\n",
       "         [0.23921569, 0.30980392, 0.35294118]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.28627451, 0.30980392, 0.30196078],\n",
       "         [0.20784314, 0.24705882, 0.26666667],\n",
       "         [0.21176471, 0.26666667, 0.31372549],\n",
       "         ...,\n",
       "         [0.06666667, 0.15686275, 0.25098039],\n",
       "         [0.08235294, 0.14117647, 0.2       ],\n",
       "         [0.12941176, 0.18823529, 0.19215686]],\n",
       "\n",
       "        [[0.23921569, 0.26666667, 0.29411765],\n",
       "         [0.21568627, 0.2745098 , 0.3372549 ],\n",
       "         [0.22352941, 0.30980392, 0.40392157],\n",
       "         ...,\n",
       "         [0.09411765, 0.18823529, 0.28235294],\n",
       "         [0.06666667, 0.1372549 , 0.20784314],\n",
       "         [0.02745098, 0.09019608, 0.1254902 ]],\n",
       "\n",
       "        [[0.17254902, 0.21960784, 0.28627451],\n",
       "         [0.18039216, 0.25882353, 0.34509804],\n",
       "         [0.19215686, 0.30196078, 0.41176471],\n",
       "         ...,\n",
       "         [0.10588235, 0.20392157, 0.30196078],\n",
       "         [0.08235294, 0.16862745, 0.25882353],\n",
       "         [0.04705882, 0.12156863, 0.19607843]]],\n",
       "\n",
       "\n",
       "       [[[0.74117647, 0.82745098, 0.94117647],\n",
       "         [0.72941176, 0.81568627, 0.9254902 ],\n",
       "         [0.7254902 , 0.81176471, 0.92156863],\n",
       "         ...,\n",
       "         [0.68627451, 0.76470588, 0.87843137],\n",
       "         [0.6745098 , 0.76078431, 0.87058824],\n",
       "         [0.6627451 , 0.76078431, 0.8627451 ]],\n",
       "\n",
       "        [[0.76078431, 0.82352941, 0.9372549 ],\n",
       "         [0.74901961, 0.81176471, 0.9254902 ],\n",
       "         [0.74509804, 0.80784314, 0.92156863],\n",
       "         ...,\n",
       "         [0.67843137, 0.75294118, 0.8627451 ],\n",
       "         [0.67058824, 0.74901961, 0.85490196],\n",
       "         [0.65490196, 0.74509804, 0.84705882]],\n",
       "\n",
       "        [[0.81568627, 0.85882353, 0.95686275],\n",
       "         [0.80392157, 0.84705882, 0.94117647],\n",
       "         [0.8       , 0.84313725, 0.9372549 ],\n",
       "         ...,\n",
       "         [0.68627451, 0.74901961, 0.85098039],\n",
       "         [0.6745098 , 0.74509804, 0.84705882],\n",
       "         [0.6627451 , 0.74901961, 0.84313725]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.81176471, 0.78039216, 0.70980392],\n",
       "         [0.79607843, 0.76470588, 0.68627451],\n",
       "         [0.79607843, 0.76862745, 0.67843137],\n",
       "         ...,\n",
       "         [0.52941176, 0.51764706, 0.49803922],\n",
       "         [0.63529412, 0.61960784, 0.58823529],\n",
       "         [0.65882353, 0.63921569, 0.59215686]],\n",
       "\n",
       "        [[0.77647059, 0.74509804, 0.66666667],\n",
       "         [0.74117647, 0.70980392, 0.62352941],\n",
       "         [0.70588235, 0.6745098 , 0.57647059],\n",
       "         ...,\n",
       "         [0.69803922, 0.67058824, 0.62745098],\n",
       "         [0.68627451, 0.6627451 , 0.61176471],\n",
       "         [0.68627451, 0.6627451 , 0.60392157]],\n",
       "\n",
       "        [[0.77647059, 0.74117647, 0.67843137],\n",
       "         [0.74117647, 0.70980392, 0.63529412],\n",
       "         [0.69803922, 0.66666667, 0.58431373],\n",
       "         ...,\n",
       "         [0.76470588, 0.72156863, 0.6627451 ],\n",
       "         [0.76862745, 0.74117647, 0.67058824],\n",
       "         [0.76470588, 0.74509804, 0.67058824]]],\n",
       "\n",
       "\n",
       "       [[[0.89803922, 0.89803922, 0.9372549 ],\n",
       "         [0.9254902 , 0.92941176, 0.96862745],\n",
       "         [0.91764706, 0.9254902 , 0.96862745],\n",
       "         ...,\n",
       "         [0.85098039, 0.85882353, 0.91372549],\n",
       "         [0.86666667, 0.8745098 , 0.91764706],\n",
       "         [0.87058824, 0.8745098 , 0.91372549]],\n",
       "\n",
       "        [[0.87058824, 0.86666667, 0.89803922],\n",
       "         [0.9372549 , 0.9372549 , 0.97647059],\n",
       "         [0.91372549, 0.91764706, 0.96470588],\n",
       "         ...,\n",
       "         [0.8745098 , 0.8745098 , 0.9254902 ],\n",
       "         [0.89019608, 0.89411765, 0.93333333],\n",
       "         [0.82352941, 0.82745098, 0.8627451 ]],\n",
       "\n",
       "        [[0.83529412, 0.80784314, 0.82745098],\n",
       "         [0.91764706, 0.90980392, 0.9372549 ],\n",
       "         [0.90588235, 0.91372549, 0.95686275],\n",
       "         ...,\n",
       "         [0.8627451 , 0.8627451 , 0.90980392],\n",
       "         [0.8627451 , 0.85882353, 0.90980392],\n",
       "         [0.79215686, 0.79607843, 0.84313725]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.58823529, 0.56078431, 0.52941176],\n",
       "         [0.54901961, 0.52941176, 0.49803922],\n",
       "         [0.51764706, 0.49803922, 0.47058824],\n",
       "         ...,\n",
       "         [0.87843137, 0.87058824, 0.85490196],\n",
       "         [0.90196078, 0.89411765, 0.88235294],\n",
       "         [0.94509804, 0.94509804, 0.93333333]],\n",
       "\n",
       "        [[0.5372549 , 0.51764706, 0.49411765],\n",
       "         [0.50980392, 0.49803922, 0.47058824],\n",
       "         [0.49019608, 0.4745098 , 0.45098039],\n",
       "         ...,\n",
       "         [0.70980392, 0.70588235, 0.69803922],\n",
       "         [0.79215686, 0.78823529, 0.77647059],\n",
       "         [0.83137255, 0.82745098, 0.81176471]],\n",
       "\n",
       "        [[0.47843137, 0.46666667, 0.44705882],\n",
       "         [0.4627451 , 0.45490196, 0.43137255],\n",
       "         [0.47058824, 0.45490196, 0.43529412],\n",
       "         ...,\n",
       "         [0.70196078, 0.69411765, 0.67843137],\n",
       "         [0.64313725, 0.64313725, 0.63529412],\n",
       "         [0.63921569, 0.63921569, 0.63137255]]]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3200bcb",
   "metadata": {},
   "source": [
    "### Convolutional Neural Netwroks - CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6fb9a8",
   "metadata": {},
   "source": [
    "VGG (Visual Geometry Group) models : The architecture involves stacking convolutional layers with small 3Ã—3 filters followed by a max pooling layer. We will first try a basic Model with 1 , 2 and 3 blocks<br>\n",
    "Moreover, it is now still one of the most popular image recognition architectures.<br>\n",
    "ReLU stands for rectified linear unit activation function; it is a piecewise linear function that will output the input if positive; otherwise, the output is zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9657899e",
   "metadata": {},
   "source": [
    "### Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c2c4197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Model - 1-block VGG\n",
    "model=Sequential()\n",
    "model.add(InputLayer(input_shape=(32,32,3)))\n",
    "model.add(Reshape(target_shape=(32,32,3)))\n",
    "model.add(Conv2D(filters=12,kernel_size=(3,3),activation='relu'))\n",
    "model.add(Conv2D(filters=12,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10)) #The dense has to be 10 because we have 10 classes in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7cc56249",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),optimizer=\"adam\",metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ba919501",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5381 - accuracy: 0.4520 - val_loss: 1.2837 - val_accuracy: 0.5522\n",
      "Epoch 2/30\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2264 - accuracy: 0.5716 - val_loss: 1.1841 - val_accuracy: 0.5874\n",
      "Epoch 3/30\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.1191 - accuracy: 0.6110 - val_loss: 1.1358 - val_accuracy: 0.6034\n",
      "Epoch 4/30\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0593 - accuracy: 0.6316 - val_loss: 1.1006 - val_accuracy: 0.6236\n",
      "Epoch 5/30\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0114 - accuracy: 0.6495 - val_loss: 1.0520 - val_accuracy: 0.6368\n",
      "Epoch 6/30\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9768 - accuracy: 0.6602 - val_loss: 1.0436 - val_accuracy: 0.6398\n",
      "Epoch 7/30\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9464 - accuracy: 0.6710 - val_loss: 1.0392 - val_accuracy: 0.6356\n",
      "Epoch 8/30\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9284 - accuracy: 0.6777 - val_loss: 1.0517 - val_accuracy: 0.6362\n",
      "Epoch 9/30\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9102 - accuracy: 0.6837 - val_loss: 1.0894 - val_accuracy: 0.6300\n",
      "Epoch 10/30\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8913 - accuracy: 0.6901 - val_loss: 1.0690 - val_accuracy: 0.6376\n",
      "Epoch 11/30\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8774 - accuracy: 0.6938 - val_loss: 1.0803 - val_accuracy: 0.6400\n",
      "Epoch 12/30\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8647 - accuracy: 0.7006 - val_loss: 1.0405 - val_accuracy: 0.6460\n",
      "Epoch 13/30\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8502 - accuracy: 0.7041 - val_loss: 1.0726 - val_accuracy: 0.6400\n",
      "Epoch 14/30\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8410 - accuracy: 0.7061 - val_loss: 1.0440 - val_accuracy: 0.6430\n",
      "Epoch 15/30\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8323 - accuracy: 0.7085 - val_loss: 1.1084 - val_accuracy: 0.6294\n",
      "Epoch 16/30\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8237 - accuracy: 0.7111 - val_loss: 1.0750 - val_accuracy: 0.6398\n",
      "Epoch 17/30\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8120 - accuracy: 0.7154 - val_loss: 1.1081 - val_accuracy: 0.6314\n",
      "Epoch 18/30\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8044 - accuracy: 0.7179 - val_loss: 1.0892 - val_accuracy: 0.6364\n",
      "Epoch 19/30\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.7967 - accuracy: 0.7217 - val_loss: 1.1041 - val_accuracy: 0.6346\n",
      "Epoch 20/30\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.7957 - accuracy: 0.7219 - val_loss: 1.1104 - val_accuracy: 0.6352\n",
      "Epoch 21/30\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 0.7859 - accuracy: 0.7251 - val_loss: 1.1364 - val_accuracy: 0.6214\n",
      "Epoch 22/30\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 0.7777 - accuracy: 0.7265 - val_loss: 1.1621 - val_accuracy: 0.6234\n",
      "Epoch 23/30\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.7755 - accuracy: 0.7272 - val_loss: 1.1473 - val_accuracy: 0.6208\n",
      "Epoch 24/30\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.7696 - accuracy: 0.7293 - val_loss: 1.1577 - val_accuracy: 0.6246\n",
      "Epoch 25/30\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.7651 - accuracy: 0.7331 - val_loss: 1.1714 - val_accuracy: 0.6144\n",
      "Epoch 26/30\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.7606 - accuracy: 0.7321 - val_loss: 1.1594 - val_accuracy: 0.6262\n",
      "Epoch 27/30\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.7573 - accuracy: 0.7344 - val_loss: 1.1295 - val_accuracy: 0.6290\n",
      "Epoch 28/30\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.7500 - accuracy: 0.7370 - val_loss: 1.1591 - val_accuracy: 0.6214\n",
      "Epoch 29/30\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.7487 - accuracy: 0.7370 - val_loss: 1.1620 - val_accuracy: 0.6258\n",
      "Epoch 30/30\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.7430 - accuracy: 0.7409 - val_loss: 1.1682 - val_accuracy: 0.6264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fab95470a0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_split=0.10,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d27292e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1737 - accuracy: 0.6221\n"
     ]
    }
   ],
   "source": [
    "_,accuracy=model.evaluate(x_test,y_test)\n",
    "#_ hata gÃ¶streyiro , evaluate deyine 1. loss 2. accuracy, _, yapmak la 1. skip yaptik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "38ba3c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1737327575683594"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4bb5c305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Model with 2 VGG blocks\n",
    "model=Sequential()\n",
    "model.add(InputLayer(input_shape=(32,32,3)))\n",
    "model.add(Reshape(target_shape=(32,32,3)))\n",
    "model.add(Conv2D(filters=12,kernel_size=(3,3),activation='relu'))\n",
    "model.add(Conv2D(filters=12,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu')) #added a second block\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c2fc8aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),optimizer=\"adam\",metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "da754d33",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1407/1407 [==============================] - 18s 12ms/step - loss: 1.6189 - accuracy: 0.4105 - val_loss: 1.3642 - val_accuracy: 0.5100\n",
      "Epoch 2/30\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2973 - accuracy: 0.5397 - val_loss: 1.1749 - val_accuracy: 0.5870\n",
      "Epoch 3/30\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1513 - accuracy: 0.5993 - val_loss: 1.1064 - val_accuracy: 0.6148\n",
      "Epoch 4/30\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0653 - accuracy: 0.6301 - val_loss: 1.0729 - val_accuracy: 0.6206\n",
      "Epoch 5/30\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.0047 - accuracy: 0.6488 - val_loss: 0.9926 - val_accuracy: 0.6454\n",
      "Epoch 6/30\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 0.9595 - accuracy: 0.6669 - val_loss: 0.9565 - val_accuracy: 0.6696\n",
      "Epoch 7/30\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9195 - accuracy: 0.6800 - val_loss: 0.9116 - val_accuracy: 0.6818\n",
      "Epoch 8/30\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.8854 - accuracy: 0.6916 - val_loss: 0.9315 - val_accuracy: 0.6774\n",
      "Epoch 9/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8547 - accuracy: 0.7020 - val_loss: 0.8676 - val_accuracy: 0.7030\n",
      "Epoch 10/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8282 - accuracy: 0.7122 - val_loss: 0.8828 - val_accuracy: 0.6934\n",
      "Epoch 11/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8074 - accuracy: 0.7212 - val_loss: 0.8637 - val_accuracy: 0.7028\n",
      "Epoch 12/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7840 - accuracy: 0.7254 - val_loss: 0.8936 - val_accuracy: 0.6928\n",
      "Epoch 13/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7646 - accuracy: 0.7335 - val_loss: 0.8535 - val_accuracy: 0.7084\n",
      "Epoch 14/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7462 - accuracy: 0.7395 - val_loss: 0.9039 - val_accuracy: 0.6966\n",
      "Epoch 15/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7340 - accuracy: 0.7443 - val_loss: 0.8493 - val_accuracy: 0.7004\n",
      "Epoch 16/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7155 - accuracy: 0.7502 - val_loss: 0.8536 - val_accuracy: 0.7096\n",
      "Epoch 17/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.6998 - accuracy: 0.7554 - val_loss: 0.8691 - val_accuracy: 0.7040\n",
      "Epoch 18/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.6876 - accuracy: 0.7581 - val_loss: 0.8721 - val_accuracy: 0.7080\n",
      "Epoch 19/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.6760 - accuracy: 0.7646 - val_loss: 0.8876 - val_accuracy: 0.7058\n",
      "Epoch 20/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.6637 - accuracy: 0.7682 - val_loss: 0.8846 - val_accuracy: 0.6980\n",
      "Epoch 21/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.6561 - accuracy: 0.7714 - val_loss: 0.8599 - val_accuracy: 0.7162\n",
      "Epoch 22/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.6453 - accuracy: 0.7760 - val_loss: 0.8520 - val_accuracy: 0.7168\n",
      "Epoch 23/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.6363 - accuracy: 0.7760 - val_loss: 0.8670 - val_accuracy: 0.7110\n",
      "Epoch 24/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.6262 - accuracy: 0.7808 - val_loss: 0.8731 - val_accuracy: 0.7124\n",
      "Epoch 25/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.6181 - accuracy: 0.7834 - val_loss: 0.9278 - val_accuracy: 0.6974\n",
      "Epoch 26/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.6094 - accuracy: 0.7860 - val_loss: 0.8783 - val_accuracy: 0.7114\n",
      "Epoch 27/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5972 - accuracy: 0.7904 - val_loss: 0.8796 - val_accuracy: 0.7168\n",
      "Epoch 28/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5969 - accuracy: 0.7901 - val_loss: 0.9020 - val_accuracy: 0.7116\n",
      "Epoch 29/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5874 - accuracy: 0.7915 - val_loss: 0.9197 - val_accuracy: 0.7036\n",
      "Epoch 30/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5828 - accuracy: 0.7949 - val_loss: 0.9191 - val_accuracy: 0.7086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fab98c2e50>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_split=0.10,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a25787e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9745 - accuracy: 0.6934\n"
     ]
    }
   ],
   "source": [
    "_,accuracy=model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9f260f",
   "metadata": {},
   "source": [
    "<font color=darkgreen>**Results for basic Models:**<br></font>\n",
    "Basic Model with **1-block VGG: 62%**<br>\n",
    "Basic Model with **2-block VGG: 69%**<br>\n",
    "Basic Model with **3-block VGG: Error on my hand..**<br>\n",
    "We can see that our results are better with 2-block VGG's<br>\n",
    "(I tried to run a 3-block VGG but it showed me an error which I couldn't solve with googling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e100db58",
   "metadata": {},
   "source": [
    "### Develop a model with Regularization for improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5350667a",
   "metadata": {},
   "source": [
    "We will try 3 different Regularitaion methods with our 2-base VGG model:<br>\n",
    "Dropout, Weight Decay and Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7a2f76",
   "metadata": {},
   "source": [
    "Try second model with Regularization techniques - **Dropout Regularization:**<br>\n",
    "Dropout is a simple technique that will randomly drop nodes out of the network. It has a regularizing effect as the remaining nodes must adapt to pick-up the slack of the removed nodes.<br>\n",
    "We use a fixed dropout rate of 20% (e.g. retain 80% of the nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "889a2eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ba4c337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model with Dropout Regularization\n",
    "model2=Sequential()\n",
    "model2.add(InputLayer(input_shape=(32,32,3)))\n",
    "model2.add(Reshape(target_shape=(32,32,3)))\n",
    "model2.add(Conv2D(filters=12,kernel_size=(3,3),activation='relu'))\n",
    "model2.add(Conv2D(filters=12,kernel_size=(3,3),activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Dropout(0.2)) # added Dropout Regularization\n",
    "model2.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu'))\n",
    "model2.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "74410eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),optimizer=\"adam\",metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f4b99044",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.6304 - accuracy: 0.4032 - val_loss: 1.3522 - val_accuracy: 0.5150\n",
      "Epoch 2/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3483 - accuracy: 0.5180 - val_loss: 1.1946 - val_accuracy: 0.5828\n",
      "Epoch 3/30\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.2366 - accuracy: 0.5622 - val_loss: 1.1167 - val_accuracy: 0.6096\n",
      "Epoch 4/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1563 - accuracy: 0.5937 - val_loss: 1.0368 - val_accuracy: 0.6334\n",
      "Epoch 5/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0947 - accuracy: 0.6133 - val_loss: 0.9949 - val_accuracy: 0.6528\n",
      "Epoch 6/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0458 - accuracy: 0.6333 - val_loss: 0.9509 - val_accuracy: 0.6696\n",
      "Epoch 7/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0086 - accuracy: 0.6453 - val_loss: 0.9151 - val_accuracy: 0.6804\n",
      "Epoch 8/30\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.9759 - accuracy: 0.6586 - val_loss: 0.8689 - val_accuracy: 0.7038\n",
      "Epoch 9/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9492 - accuracy: 0.6676 - val_loss: 0.8722 - val_accuracy: 0.6934\n",
      "Epoch 10/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9315 - accuracy: 0.6760 - val_loss: 0.8415 - val_accuracy: 0.7030\n",
      "Epoch 11/30\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.9164 - accuracy: 0.6773 - val_loss: 0.8813 - val_accuracy: 0.6896\n",
      "Epoch 12/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8996 - accuracy: 0.6848 - val_loss: 0.8183 - val_accuracy: 0.7110\n",
      "Epoch 13/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8860 - accuracy: 0.6875 - val_loss: 0.8003 - val_accuracy: 0.7150\n",
      "Epoch 14/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8739 - accuracy: 0.6927 - val_loss: 0.8442 - val_accuracy: 0.7026\n",
      "Epoch 15/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8575 - accuracy: 0.6992 - val_loss: 0.8074 - val_accuracy: 0.7174\n",
      "Epoch 16/30\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.8490 - accuracy: 0.7017 - val_loss: 0.8465 - val_accuracy: 0.7028\n",
      "Epoch 17/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8365 - accuracy: 0.7045 - val_loss: 0.7897 - val_accuracy: 0.7218\n",
      "Epoch 18/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8323 - accuracy: 0.7083 - val_loss: 0.7752 - val_accuracy: 0.7316\n",
      "Epoch 19/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8261 - accuracy: 0.7101 - val_loss: 0.7583 - val_accuracy: 0.7314\n",
      "Epoch 20/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8138 - accuracy: 0.7140 - val_loss: 0.7708 - val_accuracy: 0.7268\n",
      "Epoch 21/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8034 - accuracy: 0.7183 - val_loss: 0.7494 - val_accuracy: 0.7344\n",
      "Epoch 22/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8014 - accuracy: 0.7207 - val_loss: 0.7554 - val_accuracy: 0.7354\n",
      "Epoch 23/30\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.7976 - accuracy: 0.7204 - val_loss: 0.7701 - val_accuracy: 0.7258\n",
      "Epoch 24/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7909 - accuracy: 0.7227 - val_loss: 0.7517 - val_accuracy: 0.7326\n",
      "Epoch 25/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7814 - accuracy: 0.7260 - val_loss: 0.7728 - val_accuracy: 0.7278\n",
      "Epoch 26/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7737 - accuracy: 0.7285 - val_loss: 0.7561 - val_accuracy: 0.7372\n",
      "Epoch 27/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7752 - accuracy: 0.7291 - val_loss: 0.7803 - val_accuracy: 0.7290\n",
      "Epoch 28/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7709 - accuracy: 0.7297 - val_loss: 0.7452 - val_accuracy: 0.7354\n",
      "Epoch 29/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7680 - accuracy: 0.7298 - val_loss: 0.7307 - val_accuracy: 0.7444\n",
      "Epoch 30/30\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.7676 - accuracy: 0.7324 - val_loss: 0.7571 - val_accuracy: 0.7332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fad1ec3a90>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train,y_train,validation_split=0.10,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "30022eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7924 - accuracy: 0.7276\n"
     ]
    }
   ],
   "source": [
    "_,accuracy=model2.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd4abe8",
   "metadata": {},
   "source": [
    "Our model with Dropout has an accuray of 73% where the model without Dropout has an accuracy of 69%<br>\n",
    "We can see that Dropout performed well in our  model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7434964",
   "metadata": {},
   "source": [
    "Try another Regularization technique - **Weight Decay**:<br>\n",
    "Weight regularization or weight decay involves updating the loss function to penalize the model in proportion to the size of the model weights.<br>\n",
    "This has a regularizing effect, as larger weights result in a more complex and less stable model, whereas smaller weights are often more stable and more general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "04c24a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499a671b",
   "metadata": {},
   "source": [
    "we will use _L2 weight regularization_, the most common type used for neural networks and a sensible default weighting of 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "50e72598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model with Weight Decay\n",
    "model2=Sequential()\n",
    "model2.add(InputLayer(input_shape=(32,32,3)))\n",
    "model2.add(Reshape(target_shape=(32,32,3)))\n",
    "model2.add(Conv2D(filters=12,kernel_size=(3,3),activation='relu', kernel_regularizer=l2(0.001))) # added Weight Decay\n",
    "model2.add(Conv2D(filters=12,kernel_size=(3,3),activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model2.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e82e8ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),optimizer=\"adam\",metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a8da2d4c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.6716 - accuracy: 0.4104 - val_loss: 1.5171 - val_accuracy: 0.4758\n",
      "Epoch 2/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3890 - accuracy: 0.5253 - val_loss: 1.3232 - val_accuracy: 0.5580\n",
      "Epoch 3/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2554 - accuracy: 0.5787 - val_loss: 1.1769 - val_accuracy: 0.6154\n",
      "Epoch 4/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1661 - accuracy: 0.6167 - val_loss: 1.1193 - val_accuracy: 0.6402\n",
      "Epoch 5/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1021 - accuracy: 0.6428 - val_loss: 1.0957 - val_accuracy: 0.6452\n",
      "Epoch 6/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0588 - accuracy: 0.6589 - val_loss: 1.0812 - val_accuracy: 0.6526\n",
      "Epoch 7/30\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.0214 - accuracy: 0.6742 - val_loss: 1.0493 - val_accuracy: 0.6720\n",
      "Epoch 8/30\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.9923 - accuracy: 0.6830 - val_loss: 1.0335 - val_accuracy: 0.6786\n",
      "Epoch 9/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9687 - accuracy: 0.6921 - val_loss: 1.0148 - val_accuracy: 0.6808\n",
      "Epoch 10/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9511 - accuracy: 0.7006 - val_loss: 1.0235 - val_accuracy: 0.6724\n",
      "Epoch 11/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9267 - accuracy: 0.7091 - val_loss: 0.9987 - val_accuracy: 0.6860\n",
      "Epoch 12/30\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.9152 - accuracy: 0.7138 - val_loss: 0.9731 - val_accuracy: 0.6994\n",
      "Epoch 13/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8966 - accuracy: 0.7209 - val_loss: 0.9615 - val_accuracy: 0.7086\n",
      "Epoch 14/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8838 - accuracy: 0.7261 - val_loss: 0.9252 - val_accuracy: 0.7144\n",
      "Epoch 15/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8736 - accuracy: 0.7318 - val_loss: 0.9280 - val_accuracy: 0.7092\n",
      "Epoch 16/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8581 - accuracy: 0.7388 - val_loss: 0.9434 - val_accuracy: 0.7050\n",
      "Epoch 17/30\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.8562 - accuracy: 0.7370 - val_loss: 0.9664 - val_accuracy: 0.7014\n",
      "Epoch 18/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8434 - accuracy: 0.7434 - val_loss: 0.9134 - val_accuracy: 0.7198\n",
      "Epoch 19/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8335 - accuracy: 0.7474 - val_loss: 0.9389 - val_accuracy: 0.7134\n",
      "Epoch 20/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8327 - accuracy: 0.7442 - val_loss: 0.9507 - val_accuracy: 0.7056\n",
      "Epoch 21/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8267 - accuracy: 0.7490 - val_loss: 0.9520 - val_accuracy: 0.7062\n",
      "Epoch 22/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8169 - accuracy: 0.7515 - val_loss: 0.9468 - val_accuracy: 0.7048\n",
      "Epoch 23/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8100 - accuracy: 0.7546 - val_loss: 0.9349 - val_accuracy: 0.7220\n",
      "Epoch 24/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8107 - accuracy: 0.7547 - val_loss: 0.9297 - val_accuracy: 0.7136\n",
      "Epoch 25/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8026 - accuracy: 0.7575 - val_loss: 0.9374 - val_accuracy: 0.7130\n",
      "Epoch 26/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7950 - accuracy: 0.7617 - val_loss: 0.9390 - val_accuracy: 0.7138\n",
      "Epoch 27/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7967 - accuracy: 0.7603 - val_loss: 0.9421 - val_accuracy: 0.7148\n",
      "Epoch 28/30\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.7896 - accuracy: 0.7618 - val_loss: 0.9830 - val_accuracy: 0.7052\n",
      "Epoch 29/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7848 - accuracy: 0.7641 - val_loss: 0.9341 - val_accuracy: 0.7148\n",
      "Epoch 30/30\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.7840 - accuracy: 0.7650 - val_loss: 0.9857 - val_accuracy: 0.7086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fadf2a7580>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train,y_train,validation_split=0.10,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9403eae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0811 - accuracy: 0.6452\n"
     ]
    }
   ],
   "source": [
    "_,accuracy=model2.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b768dba0",
   "metadata": {},
   "source": [
    "Our model with Weight Decay has an accuray of 64,52%%, a worse perfomance then using Dropouts with 73%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ee51d7",
   "metadata": {},
   "source": [
    "Try **Data Augmentation**:<br>\n",
    "Data augmentation involves making copies of the examples in the training dataset with small random modifications.<br>\n",
    "It both expands the training dataset and allows the model to learn the same general features, although in a more generalized manner<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "514257e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0222cf9",
   "metadata": {},
   "source": [
    "We will investigate the effect of simple augmentation on the baseline image, specifically horizontal flips and 10% shifts in the height and width of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3194dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data generator\n",
    "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "# prepare iterator\n",
    "it_train = datagen.flow(x_train, y_train, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ef711e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=Sequential()\n",
    "model2.add(InputLayer(input_shape=(32,32,3)))\n",
    "model2.add(Reshape(target_shape=(32,32,3)))\n",
    "model2.add(Conv2D(filters=12,kernel_size=(3,3),activation='relu',))\n",
    "model2.add(Conv2D(filters=12,kernel_size=(3,3),activation='relu',))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu',))\n",
    "model2.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu',))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2b94aac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),optimizer=\"adam\",metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "002b6e80",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "781/781 [==============================] - 20s 25ms/step - loss: 1.7380 - accuracy: 0.1080 - val_loss: 1.4475 - val_accuracy: 0.0663\n",
      "Epoch 2/30\n",
      "781/781 [==============================] - 19s 24ms/step - loss: 1.4707 - accuracy: 0.0966 - val_loss: 1.4341 - val_accuracy: 0.1277\n",
      "Epoch 3/30\n",
      "781/781 [==============================] - 19s 24ms/step - loss: 1.3380 - accuracy: 0.0953 - val_loss: 1.2347 - val_accuracy: 0.0904\n",
      "Epoch 4/30\n",
      "781/781 [==============================] - 19s 24ms/step - loss: 1.2615 - accuracy: 0.0966 - val_loss: 1.1105 - val_accuracy: 0.0951\n",
      "Epoch 5/30\n",
      "781/781 [==============================] - 19s 25ms/step - loss: 1.2037 - accuracy: 0.0961 - val_loss: 1.0912 - val_accuracy: 0.1067\n",
      "Epoch 6/30\n",
      "781/781 [==============================] - 19s 25ms/step - loss: 1.1649 - accuracy: 0.0977 - val_loss: 1.1755 - val_accuracy: 0.0780\n",
      "Epoch 7/30\n",
      "781/781 [==============================] - 19s 24ms/step - loss: 1.1262 - accuracy: 0.0971 - val_loss: 1.1678 - val_accuracy: 0.0826\n",
      "Epoch 8/30\n",
      "781/781 [==============================] - 19s 25ms/step - loss: 1.1022 - accuracy: 0.0988 - val_loss: 1.0619 - val_accuracy: 0.0950\n",
      "Epoch 9/30\n",
      "781/781 [==============================] - 19s 24ms/step - loss: 1.0782 - accuracy: 0.0992 - val_loss: 1.1206 - val_accuracy: 0.0970\n",
      "Epoch 10/30\n",
      "781/781 [==============================] - 19s 24ms/step - loss: 1.0526 - accuracy: 0.1010 - val_loss: 1.0053 - val_accuracy: 0.1001\n",
      "Epoch 11/30\n",
      "781/781 [==============================] - 19s 24ms/step - loss: 1.0336 - accuracy: 0.0999 - val_loss: 1.0263 - val_accuracy: 0.0820\n",
      "Epoch 12/30\n",
      "781/781 [==============================] - 19s 25ms/step - loss: 1.0157 - accuracy: 0.0993 - val_loss: 1.0121 - val_accuracy: 0.0897\n",
      "Epoch 13/30\n",
      "781/781 [==============================] - 19s 25ms/step - loss: 1.0028 - accuracy: 0.1010 - val_loss: 0.9717 - val_accuracy: 0.0984\n",
      "Epoch 14/30\n",
      "781/781 [==============================] - 19s 25ms/step - loss: 0.9850 - accuracy: 0.1004 - val_loss: 0.9554 - val_accuracy: 0.0878\n",
      "Epoch 15/30\n",
      "781/781 [==============================] - 19s 25ms/step - loss: 0.9768 - accuracy: 0.1004 - val_loss: 0.8940 - val_accuracy: 0.1028\n",
      "Epoch 16/30\n",
      "781/781 [==============================] - 19s 24ms/step - loss: 0.9688 - accuracy: 0.0991 - val_loss: 0.9348 - val_accuracy: 0.1013\n",
      "Epoch 17/30\n",
      "781/781 [==============================] - 19s 24ms/step - loss: 0.9552 - accuracy: 0.1006 - val_loss: 0.9509 - val_accuracy: 0.0824\n",
      "Epoch 18/30\n",
      "781/781 [==============================] - 19s 24ms/step - loss: 0.9512 - accuracy: 0.1007 - val_loss: 0.9226 - val_accuracy: 0.1118\n",
      "Epoch 19/30\n",
      "781/781 [==============================] - 19s 24ms/step - loss: 0.9367 - accuracy: 0.1012 - val_loss: 0.9442 - val_accuracy: 0.0963\n",
      "Epoch 20/30\n",
      "781/781 [==============================] - 19s 24ms/step - loss: 0.9285 - accuracy: 0.1006 - val_loss: 0.9231 - val_accuracy: 0.0872\n",
      "Epoch 21/30\n",
      "781/781 [==============================] - 19s 24ms/step - loss: 0.9172 - accuracy: 0.1005 - val_loss: 0.8827 - val_accuracy: 0.0923\n",
      "Epoch 22/30\n",
      "781/781 [==============================] - 20s 25ms/step - loss: 0.9078 - accuracy: 0.1007 - val_loss: 0.8991 - val_accuracy: 0.0990\n",
      "Epoch 23/30\n",
      "781/781 [==============================] - 20s 25ms/step - loss: 0.8967 - accuracy: 0.1004 - val_loss: 0.8725 - val_accuracy: 0.0869\n",
      "Epoch 24/30\n",
      "781/781 [==============================] - 20s 26ms/step - loss: 0.8971 - accuracy: 0.1010 - val_loss: 0.8609 - val_accuracy: 0.0995\n",
      "Epoch 25/30\n",
      "781/781 [==============================] - 20s 25ms/step - loss: 0.8847 - accuracy: 0.1009 - val_loss: 0.8573 - val_accuracy: 0.0968\n",
      "Epoch 26/30\n",
      "781/781 [==============================] - 20s 25ms/step - loss: 0.8777 - accuracy: 0.1021 - val_loss: 0.8775 - val_accuracy: 0.0992\n",
      "Epoch 27/30\n",
      "781/781 [==============================] - 20s 25ms/step - loss: 0.8670 - accuracy: 0.1008 - val_loss: 0.8717 - val_accuracy: 0.1084\n",
      "Epoch 28/30\n",
      "781/781 [==============================] - 20s 25ms/step - loss: 0.8643 - accuracy: 0.1000 - val_loss: 0.8330 - val_accuracy: 0.0833\n",
      "Epoch 29/30\n",
      "781/781 [==============================] - 20s 25ms/step - loss: 0.8600 - accuracy: 0.1010 - val_loss: 0.8543 - val_accuracy: 0.1005\n",
      "Epoch 30/30\n",
      "781/781 [==============================] - 20s 25ms/step - loss: 0.8498 - accuracy: 0.1003 - val_loss: 0.8592 - val_accuracy: 0.1035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fad5c2ceb0>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = int(x_train.shape[0] / 64)\n",
    "model2.fit(it_train, steps_per_epoch=steps, epochs=30, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b44bacdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.8592 - accuracy: 0.1035\n"
     ]
    }
   ],
   "source": [
    "_,accuracy=model2.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0521eb96",
   "metadata": {},
   "source": [
    "I think I didn't do the Data Augmentation right, because the results should be more than 10%...<br>\n",
    "I hope prof. Zafer can help me with this problem later on and try to understand how to implement Data Augmentation (if it is a helpfull method)... :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0859fe4c",
   "metadata": {},
   "source": [
    "<font color=darkgreen>**Results for models with Regularization methods:**<br></font>\n",
    "Model with **Dropout: 73%**<br>\n",
    "Model with **Weight Decay: 64,52%**<br>\n",
    "(Model with **Data Augmentation: 10%***)<br>\n",
    "We can see that our results are better when using Dropout instead of Weight Decay method.<br>\n",
    "(*Data Augmentation was a failure on my end and the result is probably not right so I am going to ignore this method for now.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3678508",
   "metadata": {},
   "source": [
    "### Try to further improve Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f8ae66",
   "metadata": {},
   "source": [
    "Our Results show us that the Dropout methos had a good effect on our accuracy score. So we can try to look more into Dropout methods.<br>\n",
    "We will try to **increace the dropout percentage** for each block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "84534028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model with increased Dropout Regularization\n",
    "model3=Sequential()\n",
    "model3.add(InputLayer(input_shape=(32,32,3)))\n",
    "model3.add(Reshape(target_shape=(32,32,3)))\n",
    "model3.add(Conv2D(filters=12,kernel_size=(3,3),activation='relu'))\n",
    "model3.add(Conv2D(filters=12,kernel_size=(3,3),activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu'))\n",
    "model3.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model3.add(Dropout(0.4)) # increase the dropout percentage from 0.2 to 0.4\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "72be903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),optimizer=\"adam\",metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "da7b00a6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.6620 - accuracy: 0.3883 - val_loss: 1.3658 - val_accuracy: 0.5144\n",
      "Epoch 2/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3690 - accuracy: 0.5065 - val_loss: 1.2602 - val_accuracy: 0.5558\n",
      "Epoch 3/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2642 - accuracy: 0.5493 - val_loss: 1.2325 - val_accuracy: 0.5696\n",
      "Epoch 4/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1821 - accuracy: 0.5790 - val_loss: 1.0293 - val_accuracy: 0.6312\n",
      "Epoch 5/30\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.1187 - accuracy: 0.6031 - val_loss: 0.9892 - val_accuracy: 0.6506\n",
      "Epoch 6/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0766 - accuracy: 0.6192 - val_loss: 1.0163 - val_accuracy: 0.6444\n",
      "Epoch 7/30\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.0421 - accuracy: 0.6322 - val_loss: 0.9571 - val_accuracy: 0.6608\n",
      "Epoch 8/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0166 - accuracy: 0.6412 - val_loss: 0.9200 - val_accuracy: 0.6800\n",
      "Epoch 9/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9875 - accuracy: 0.6520 - val_loss: 0.8818 - val_accuracy: 0.6900\n",
      "Epoch 10/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9688 - accuracy: 0.6597 - val_loss: 0.8385 - val_accuracy: 0.7062\n",
      "Epoch 11/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9518 - accuracy: 0.6650 - val_loss: 0.8834 - val_accuracy: 0.6964\n",
      "Epoch 12/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9390 - accuracy: 0.6689 - val_loss: 0.8168 - val_accuracy: 0.7144\n",
      "Epoch 13/30\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.9244 - accuracy: 0.6722 - val_loss: 0.8087 - val_accuracy: 0.7124\n",
      "Epoch 14/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9161 - accuracy: 0.6770 - val_loss: 0.8355 - val_accuracy: 0.7042\n",
      "Epoch 15/30\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9084 - accuracy: 0.6771 - val_loss: 0.7902 - val_accuracy: 0.7228\n",
      "Epoch 16/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8967 - accuracy: 0.6828 - val_loss: 0.8015 - val_accuracy: 0.7238\n",
      "Epoch 17/30\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.8888 - accuracy: 0.6874 - val_loss: 0.7859 - val_accuracy: 0.7218\n",
      "Epoch 18/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8871 - accuracy: 0.6860 - val_loss: 0.7918 - val_accuracy: 0.7258\n",
      "Epoch 19/30\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.8821 - accuracy: 0.6900 - val_loss: 0.8286 - val_accuracy: 0.7144\n",
      "Epoch 20/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8760 - accuracy: 0.6918 - val_loss: 0.7951 - val_accuracy: 0.7162\n",
      "Epoch 21/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8662 - accuracy: 0.6953 - val_loss: 0.7583 - val_accuracy: 0.7298\n",
      "Epoch 22/30\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.8675 - accuracy: 0.6932 - val_loss: 0.7731 - val_accuracy: 0.7300\n",
      "Epoch 23/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8540 - accuracy: 0.6984 - val_loss: 0.7647 - val_accuracy: 0.7346\n",
      "Epoch 24/30\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.8543 - accuracy: 0.6978 - val_loss: 0.8117 - val_accuracy: 0.7188\n",
      "Epoch 25/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8534 - accuracy: 0.6998 - val_loss: 0.7936 - val_accuracy: 0.7286\n",
      "Epoch 26/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8485 - accuracy: 0.7019 - val_loss: 0.7781 - val_accuracy: 0.7262\n",
      "Epoch 27/30\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.8447 - accuracy: 0.7011 - val_loss: 0.7867 - val_accuracy: 0.7248\n",
      "Epoch 28/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8446 - accuracy: 0.7009 - val_loss: 0.7585 - val_accuracy: 0.7322\n",
      "Epoch 29/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8384 - accuracy: 0.7065 - val_loss: 0.7574 - val_accuracy: 0.7394\n",
      "Epoch 30/30\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8361 - accuracy: 0.7048 - val_loss: 0.8129 - val_accuracy: 0.7192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fac3691d90>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_train,y_train,validation_split=0.10,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "62b2aafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.8279 - accuracy: 0.7072\n"
     ]
    }
   ],
   "source": [
    "_,accuracy=model3.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8ca731",
   "metadata": {},
   "source": [
    "in our model, increasing the dropout rate leads to a less accuracy with 71%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d6d09dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model with increased filters and Dropout Regularization\n",
    "model3=Sequential()\n",
    "model3.add(InputLayer(input_shape=(32,32,3)))\n",
    "model3.add(Reshape(target_shape=(32,32,3)))\n",
    "model3.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu')) # increased filter from 12 to 32\n",
    "model3.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu')) # increased filter from 32 to 64\n",
    "model3.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model3.add(Dropout(0.4)) #we increased the dropout percentage from 0.2 to 0.4\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "04477f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),optimizer=\"adam\",metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2b12b140",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1407/1407 [==============================] - 34s 24ms/step - loss: 1.5976 - accuracy: 0.4160 - val_loss: 1.2551 - val_accuracy: 0.5438\n",
      "Epoch 2/30\n",
      "1407/1407 [==============================] - 34s 24ms/step - loss: 1.2099 - accuracy: 0.5714 - val_loss: 1.0703 - val_accuracy: 0.6278\n",
      "Epoch 3/30\n",
      "1407/1407 [==============================] - 34s 24ms/step - loss: 1.0462 - accuracy: 0.6303 - val_loss: 0.8835 - val_accuracy: 0.6926\n",
      "Epoch 4/30\n",
      "1407/1407 [==============================] - 34s 24ms/step - loss: 0.9531 - accuracy: 0.6647 - val_loss: 0.8202 - val_accuracy: 0.7160\n",
      "Epoch 5/30\n",
      "1407/1407 [==============================] - 33s 23ms/step - loss: 0.8917 - accuracy: 0.6871 - val_loss: 0.7886 - val_accuracy: 0.7316\n",
      "Epoch 6/30\n",
      "1407/1407 [==============================] - 33s 23ms/step - loss: 0.8491 - accuracy: 0.7014 - val_loss: 0.7677 - val_accuracy: 0.7320\n",
      "Epoch 7/30\n",
      "1407/1407 [==============================] - 33s 24ms/step - loss: 0.8204 - accuracy: 0.7123 - val_loss: 0.7347 - val_accuracy: 0.7424\n",
      "Epoch 8/30\n",
      "1407/1407 [==============================] - 33s 24ms/step - loss: 0.7863 - accuracy: 0.7231 - val_loss: 0.7283 - val_accuracy: 0.7454\n",
      "Epoch 9/30\n",
      "1407/1407 [==============================] - 33s 23ms/step - loss: 0.7690 - accuracy: 0.7287 - val_loss: 0.7025 - val_accuracy: 0.7570\n",
      "Epoch 10/30\n",
      "1407/1407 [==============================] - 34s 24ms/step - loss: 0.7442 - accuracy: 0.7386 - val_loss: 0.6822 - val_accuracy: 0.7626\n",
      "Epoch 11/30\n",
      "1407/1407 [==============================] - 34s 24ms/step - loss: 0.7351 - accuracy: 0.7424 - val_loss: 0.6739 - val_accuracy: 0.7666\n",
      "Epoch 12/30\n",
      "1407/1407 [==============================] - 34s 24ms/step - loss: 0.7153 - accuracy: 0.7472 - val_loss: 0.6943 - val_accuracy: 0.7556\n",
      "Epoch 13/30\n",
      "1407/1407 [==============================] - 33s 24ms/step - loss: 0.7003 - accuracy: 0.7554 - val_loss: 0.6877 - val_accuracy: 0.7618\n",
      "Epoch 14/30\n",
      "1407/1407 [==============================] - 33s 24ms/step - loss: 0.6916 - accuracy: 0.7593 - val_loss: 0.6829 - val_accuracy: 0.7658\n",
      "Epoch 15/30\n",
      "1407/1407 [==============================] - 33s 24ms/step - loss: 0.6871 - accuracy: 0.7602 - val_loss: 0.6734 - val_accuracy: 0.7676\n",
      "Epoch 16/30\n",
      "1407/1407 [==============================] - 33s 24ms/step - loss: 0.6716 - accuracy: 0.7634 - val_loss: 0.6632 - val_accuracy: 0.7698\n",
      "Epoch 17/30\n",
      "1407/1407 [==============================] - 33s 23ms/step - loss: 0.6590 - accuracy: 0.7684 - val_loss: 0.6739 - val_accuracy: 0.7710\n",
      "Epoch 18/30\n",
      "1407/1407 [==============================] - 33s 24ms/step - loss: 0.6491 - accuracy: 0.7738 - val_loss: 0.6647 - val_accuracy: 0.7712\n",
      "Epoch 19/30\n",
      "1407/1407 [==============================] - 33s 23ms/step - loss: 0.6465 - accuracy: 0.7722 - val_loss: 0.6722 - val_accuracy: 0.7702\n",
      "Epoch 20/30\n",
      "1407/1407 [==============================] - 34s 24ms/step - loss: 0.6384 - accuracy: 0.7748 - val_loss: 0.6464 - val_accuracy: 0.7748\n",
      "Epoch 21/30\n",
      "1407/1407 [==============================] - 34s 24ms/step - loss: 0.6324 - accuracy: 0.7758 - val_loss: 0.6719 - val_accuracy: 0.7742\n",
      "Epoch 22/30\n",
      "1407/1407 [==============================] - 33s 24ms/step - loss: 0.6205 - accuracy: 0.7806 - val_loss: 0.6616 - val_accuracy: 0.7744\n",
      "Epoch 23/30\n",
      "1407/1407 [==============================] - 33s 24ms/step - loss: 0.6217 - accuracy: 0.7806 - val_loss: 0.6648 - val_accuracy: 0.7734\n",
      "Epoch 24/30\n",
      "1407/1407 [==============================] - 33s 24ms/step - loss: 0.6074 - accuracy: 0.7889 - val_loss: 0.6909 - val_accuracy: 0.7640\n",
      "Epoch 25/30\n",
      "1407/1407 [==============================] - 33s 23ms/step - loss: 0.6077 - accuracy: 0.7859 - val_loss: 0.6516 - val_accuracy: 0.7798\n",
      "Epoch 26/30\n",
      "1407/1407 [==============================] - 33s 24ms/step - loss: 0.6035 - accuracy: 0.7858 - val_loss: 0.7034 - val_accuracy: 0.7612\n",
      "Epoch 27/30\n",
      "1407/1407 [==============================] - 33s 24ms/step - loss: 0.6022 - accuracy: 0.7887 - val_loss: 0.6910 - val_accuracy: 0.7688\n",
      "Epoch 28/30\n",
      "1407/1407 [==============================] - 34s 24ms/step - loss: 0.5871 - accuracy: 0.7944 - val_loss: 0.6500 - val_accuracy: 0.7814\n",
      "Epoch 29/30\n",
      "1407/1407 [==============================] - 34s 24ms/step - loss: 0.5877 - accuracy: 0.7921 - val_loss: 0.6436 - val_accuracy: 0.7840\n",
      "Epoch 30/30\n",
      "1407/1407 [==============================] - 33s 24ms/step - loss: 0.5783 - accuracy: 0.7969 - val_loss: 0.6526 - val_accuracy: 0.7786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fabd165d30>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_train,y_train,validation_split=0.10,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b538873a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 5ms/step - loss: 0.6952 - accuracy: 0.7625\n"
     ]
    }
   ],
   "source": [
    "_,accuracy=model3.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab85d637",
   "metadata": {},
   "source": [
    "when increasing the filters from the Conv2D we get a result of 76%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d28dea",
   "metadata": {},
   "source": [
    "Adding **Batch Normalization**:<br>\n",
    "Batch normalization is a technique designed to automatically standardize the inputs to a layer in a deep learning neural network. <br>\n",
    "It has the effect of dramatically accelerating the training process of a neural network, and in some cases improves the performance of the model via a modest regularization effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5d106c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d48e6bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model with Batch Normalization\n",
    "model3=Sequential()\n",
    "model3.add(InputLayer(input_shape=(32,32,3)))\n",
    "model3.add(Reshape(target_shape=(32,32,3)))\n",
    "model3.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu')) # increased filter from 12 to 32\n",
    "model3.add(BatchNormalization()) #added Batch Normalization\n",
    "model3.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu'))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu')) # increased filter from 32 to 64\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu'))\n",
    "model3.add(BatchNormalization()) #added Batch Normalization\n",
    "model3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model3.add(Dropout(0.4)) #we increased the dropout percentage from 0.2 to 0.4\n",
    "model3.add(Flatten())\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "12135ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),optimizer=\"adam\",metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "baff3c10",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1407/1407 [==============================] - 43s 30ms/step - loss: 1.5824 - accuracy: 0.4603 - val_loss: 1.2464 - val_accuracy: 0.5646\n",
      "Epoch 2/30\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 1.1326 - accuracy: 0.6070 - val_loss: 1.0864 - val_accuracy: 0.6294\n",
      "Epoch 3/30\n",
      "1407/1407 [==============================] - 40s 29ms/step - loss: 1.0097 - accuracy: 0.6512 - val_loss: 1.0393 - val_accuracy: 0.6386\n",
      "Epoch 4/30\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9219 - accuracy: 0.6811 - val_loss: 0.9889 - val_accuracy: 0.6634\n",
      "Epoch 5/30\n",
      "1407/1407 [==============================] - 40s 28ms/step - loss: 0.8804 - accuracy: 0.6961 - val_loss: 0.9085 - val_accuracy: 0.6906\n",
      "Epoch 6/30\n",
      "1407/1407 [==============================] - 40s 28ms/step - loss: 0.8271 - accuracy: 0.7150 - val_loss: 0.7773 - val_accuracy: 0.7320\n",
      "Epoch 7/30\n",
      "1407/1407 [==============================] - 39s 28ms/step - loss: 0.7951 - accuracy: 0.7267 - val_loss: 0.7457 - val_accuracy: 0.7428\n",
      "Epoch 8/30\n",
      "1407/1407 [==============================] - 39s 28ms/step - loss: 0.7613 - accuracy: 0.7361 - val_loss: 0.7303 - val_accuracy: 0.7542\n",
      "Epoch 9/30\n",
      "1407/1407 [==============================] - 39s 28ms/step - loss: 0.7358 - accuracy: 0.7466 - val_loss: 0.6875 - val_accuracy: 0.7698\n",
      "Epoch 10/30\n",
      "1407/1407 [==============================] - 39s 28ms/step - loss: 0.7106 - accuracy: 0.7524 - val_loss: 0.7098 - val_accuracy: 0.7602\n",
      "Epoch 11/30\n",
      "1407/1407 [==============================] - 39s 28ms/step - loss: 0.6903 - accuracy: 0.7615 - val_loss: 0.6953 - val_accuracy: 0.7606\n",
      "Epoch 12/30\n",
      "1407/1407 [==============================] - 39s 28ms/step - loss: 0.6715 - accuracy: 0.7658 - val_loss: 0.7013 - val_accuracy: 0.7658\n",
      "Epoch 13/30\n",
      "1407/1407 [==============================] - 40s 29ms/step - loss: 0.6544 - accuracy: 0.7723 - val_loss: 0.6367 - val_accuracy: 0.7890\n",
      "Epoch 14/30\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.6352 - accuracy: 0.7796 - val_loss: 0.6640 - val_accuracy: 0.7752\n",
      "Epoch 15/30\n",
      "1407/1407 [==============================] - 42s 30ms/step - loss: 0.6307 - accuracy: 0.7810 - val_loss: 0.6655 - val_accuracy: 0.7746\n",
      "Epoch 16/30\n",
      "1407/1407 [==============================] - 42s 30ms/step - loss: 0.6178 - accuracy: 0.7844 - val_loss: 0.6571 - val_accuracy: 0.7846\n",
      "Epoch 17/30\n",
      "1407/1407 [==============================] - 42s 30ms/step - loss: 0.6010 - accuracy: 0.7906 - val_loss: 0.6074 - val_accuracy: 0.8016\n",
      "Epoch 18/30\n",
      "1407/1407 [==============================] - 42s 30ms/step - loss: 0.5979 - accuracy: 0.7907 - val_loss: 0.5851 - val_accuracy: 0.8046\n",
      "Epoch 19/30\n",
      "1407/1407 [==============================] - 42s 30ms/step - loss: 0.5836 - accuracy: 0.7954 - val_loss: 0.6334 - val_accuracy: 0.7890\n",
      "Epoch 20/30\n",
      "1407/1407 [==============================] - 43s 30ms/step - loss: 0.5740 - accuracy: 0.7993 - val_loss: 0.6205 - val_accuracy: 0.7982\n",
      "Epoch 21/30\n",
      "1407/1407 [==============================] - 43s 31ms/step - loss: 0.5669 - accuracy: 0.8014 - val_loss: 0.6056 - val_accuracy: 0.7960\n",
      "Epoch 22/30\n",
      "1407/1407 [==============================] - 43s 30ms/step - loss: 0.5561 - accuracy: 0.8048 - val_loss: 0.5938 - val_accuracy: 0.8022\n",
      "Epoch 23/30\n",
      "1407/1407 [==============================] - 43s 31ms/step - loss: 0.5522 - accuracy: 0.8076 - val_loss: 0.6172 - val_accuracy: 0.7912\n",
      "Epoch 24/30\n",
      "1407/1407 [==============================] - 42s 30ms/step - loss: 0.5483 - accuracy: 0.8074 - val_loss: 0.5910 - val_accuracy: 0.8024\n",
      "Epoch 25/30\n",
      "1407/1407 [==============================] - 42s 30ms/step - loss: 0.5365 - accuracy: 0.8123 - val_loss: 0.6255 - val_accuracy: 0.7930\n",
      "Epoch 26/30\n",
      "1407/1407 [==============================] - 42s 30ms/step - loss: 0.5359 - accuracy: 0.8131 - val_loss: 0.5944 - val_accuracy: 0.8020\n",
      "Epoch 27/30\n",
      "1407/1407 [==============================] - 42s 30ms/step - loss: 0.5232 - accuracy: 0.8165 - val_loss: 0.6490 - val_accuracy: 0.7910\n",
      "Epoch 28/30\n",
      "1407/1407 [==============================] - 42s 30ms/step - loss: 0.5177 - accuracy: 0.8188 - val_loss: 0.5795 - val_accuracy: 0.8128\n",
      "Epoch 29/30\n",
      "1407/1407 [==============================] - 45s 32ms/step - loss: 0.5187 - accuracy: 0.8208 - val_loss: 0.6205 - val_accuracy: 0.7886\n",
      "Epoch 30/30\n",
      "1407/1407 [==============================] - 46s 32ms/step - loss: 0.5074 - accuracy: 0.8218 - val_loss: 0.6406 - val_accuracy: 0.7898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fabe08fdc0>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_train,y_train,validation_split=0.10,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "38301146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6777 - accuracy: 0.7748\n"
     ]
    }
   ],
   "source": [
    "_,accuracy=model3.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3fefae",
   "metadata": {},
   "source": [
    "Adding Batch Normalization increased our results slightly to 77%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c26f4b",
   "metadata": {},
   "source": [
    "<font color=darkgreen>**Results:**<br></font>\n",
    "Model with **increased Dropout: 71%**<br>\n",
    "Model with **incresed Dropout and Filter: 76%**<br>\n",
    "Model with **incresed Dropout and Filter with Batch Normalization: 77%**<br>\n",
    "Our best model is with increased Dropout, Filters and adding Batch Normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95d2dec",
   "metadata": {},
   "source": [
    "Now lets bring our best model home to colab and try with more epochs, otherwise my PC is going to explode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90db7b12",
   "metadata": {},
   "source": [
    "On Colab, with an epoch of 200 our result ended with an accuracy of 81,62%"
   ]
  },
  {
   "attachments": {
    "colab_results.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "3723cc34",
   "metadata": {},
   "source": [
    "![colab_results.png](attachment:colab_results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549a01ed",
   "metadata": {},
   "source": [
    "### What I learned while trying to solve this project:\n",
    "At first I had no Idea how to approach this project, because I did not fully understand the concept behindt it in our lessons. I did run the few code lines, which we learned in the MNIST example with the CIFAR dataset and had an accuracy of only 55% and thought this can't be all there is to it. With the help of the internet I learned step by step new things and want to share them, so it can be helpful to our other members in our bootcamp and also a little summary for myself.<br>\n",
    "<br>\n",
    "* <font color=darkgreen>**Model Archcitectures:**</font><br>I learned that there are a good amount of different architecture types for CNN models like LeNet, ResNet, VGG etc. For example VGG involves stacking layers with small 3x3 filters followed by a max pooling layer\n",
    "* <font color=darkgreen>**Filters:**</font><br>The number of filters in each block is increased with the depth of the network such as 32, 64, 128, 256. By increasing them the results can get better\n",
    "* <font color=darkgreen>**Regularizations:**</font><br>Regularization methods help to adress rapid overfitting of the test dataset, by slowing down the rate of learning of the model. For example Dropout our Weight Decay Regularizations.\n",
    "* <font color=darkgreen>**Data Augmentation:**</font><br>By copying the examples in the training dataest with small random modifications, such as horizontal flip, minor shifts of image or small zooming, croppin etc., data augmentation expands the training dataset and allows the model to learn in a more generalized manner\n",
    "* <font color=darkgreen>**Batch Normalization**</font><br>\n",
    "* <font color=darkgreen>**Combining different mehtods:**</font><br>You can combine all of the above and try to see which methods work better together to achieve better results.\n",
    "<br>\n",
    "* <h3> Don't use Jupyter because it took so much time just to load one of the models with just only 30 epochs, while running this on colab with GPU Runtime made it so much faster even with 200 epochs...(I wrote this last part way later after realising this.. and now I am crying for all the lost time I spend.. :) </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d8b8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
